# メモ

ノンリファレンス画像品質評価（NR-IQA）の主要論文（2019–2025）

MUSIQ (2021年, Keら)

発表年: 2021年

モデル名／著者: MUSIQ (Junjie Ke ら)

アーキテクチャ／技術特徴: ViTベースのパッチ型Transformerで、可変解像度やアスペクト比の入力をそのまま扱えるマルチスケール対応モデル。画像を複数解像度に変換したマルチスケール表現を用い、ハッシュベースの2D位置埋め込みとスケール埋め込みを導入することで、異なるスケール・位置の情報を同時に注意機構で処理する。

主なデータセット: PaQ-2-PiQ、KonIQ-10k、SPAQ、AVA（技術品質・美的品質に関する大規模データセット）。

貢献: 画像をフルサイズで入力でき、複数スケールの特徴を効果的に統合できるTransformer枠組みを初めて提案した。これにより多種多様な歪みに対処でき、PaQ-2-PiQやKonIQ-10kなどで従来比大幅に精度を向上し、3つの技術品質ベンチマークで最先端性能を達成した。


MANIQA (2022年, Yangら)

発表年: 2022年

モデル名／著者: MANIQA (Sidi Yang ら)

アーキテクチャ／技術特徴: 画像からまずVision Transformer (ViT) で特徴を抽出し、全体的な歪みと局所的な歪みの両方を捉えるために二種類の注意ブロックを組み合わせる。具体的には**Transposed Attention Block (TAB)**でチャネル次元上のグローバル相関を、Scale Swin Transformer Block (SSTB)で空間次元上の局所相関を計算する。さらに、画像を細分化した各パッチに重みを付けて品質スコアを推定する二分岐構造を持つ。

主なデータセット: LIVE、TID2013、CSIQ、KADID-10Kなどの標準的歪みデータセット。加えて、NTIRE 2022の「Perceptual IQA (No-Reference)」チャレンジで1位を獲得している。

貢献: GAN生成による複雑な復元画像の品質評価に強みを持ち、従来手法を大きく上回る精度を達成した。提案モデルは上記の標準データセットでSOTA精度を記録し、実務的にもNTIRE2022チャレンジ優勝など高い性能を示した。独自の注意モジュールは以後の研究にも影響を与えている。


QPT (2023年, Zhaoら)

発表年: 2023年 (CVPR 2023)

モデル名／著者: QPT (Kai Zhao ら)

アーキテクチャ／技術特徴: 大規模データセット（ImageNet）上で自己教師あり学習を行うBIQA事前学習モデル。品質認識型のコントラスト学習損失を導入し、同一画像内の異なる劣化パッチ間で「品質が同じであるべき」という仮定のもとで特徴表現を学習する。改良した劣化合成プロセスにより約2億通りの劣化画像を生成・学習することで、画像品質に特化した表現を獲得する。

主なデータセット: ImageNetデータで事前学習後、CLIVE、KonIQ-10k、SPAQAなど既存のBIQAデータセットで評価。大規模ラベルなしデータから学習したモデルは、これらのデータセットで高い汎化性能を示す。

貢献: 画像品質評価特化の自己教師あり事前学習フレームワークを提案し、従来比で大幅に性能を向上させた。大規模な汎用画像データセットを品質評価タスクに転用する新しいアプローチであり、ラベル付きデータが少ないBIQA分野への有効な道を示した。


ARNIQA (2024年, Agnolucciら)

発表年: 2024年 (WACV 2024)

モデル名／著者: ARNIQA (Lorenzo Agnolucci ら)

アーキテクチャ／技術特徴: 画像に連続的かつ順序付けられた複数の劣化を合成的に適用する新しい劣化モデルを設計。劣化モデルによって生成される「同じ組み合わせの歪みを受けた異なる画像」のパッチ表現間で類似度を最大化する自己教師あり学習を行い、劣化マニフォールド上で隣接する特徴表現を学習する。学習後はエンコーダを固定し、線形回帰器で画像品質スコアを予測する。

主なデータセット: CLIVE、KonIQ-10k、KADID-10Kなど複数の品質評価データセット。自己教師あり学習により、従来と比べて少量データでも高い性能を実現した。

貢献: MOSラベル不要で歪み特徴を学習し、従来手法を上回る高精度を達成した。学習済みモデルのファインチューニングを行わずに良質な特徴表現を獲得でき、データ効率や一般化能力、ロバスト性が向上している。


DP-IQA (2024年, Fuら)

発表年: 2024年 (arXiv)

モデル名／著者: DP-IQA (Honghao Fu ら)

アーキテクチャ／技術特徴: Stable Diffusionなどのテキスト→画像拡散モデルの事前学習済みUNetを利用して特徴を抽出する新手法。拡散モデルのデノイザからマルチレベルの特徴を取り出すため、テキストプロンプト用のアダプタと画像用のアダプタを導入し、得られた表現を軽量なCNNモデルに蒸留する。

主なデータセット: KonIQ-10k、CLIVE、SPAQなどの実世界歪みデータセット（In-the-wild）。学習にはこれらのデータセットに加えて、拡散モデルの事前学習データも活用した。

貢献: 画像品質評価に生成モデルの事前知識を初適用し、広範な実画像歪みデータでSOTA性能を達成。拡散モデルの潜在表現（テキスト誘導型の特徴）が品質認識に有用であることを示した先駆的研究であり、以前のCNN/Transformer手法を大きく上回る汎化性能を示した。


GenzIQA (2024年, Deら)

発表年: 2024年 (arXiv)

モデル名／著者: GenzIQA (Diptanu De ら)

アーキテクチャ／技術特徴: 潜在拡散モデル（例: Stable Diffusion）のクロスアテンション機構を利用し、画像品質評価に応用する。拡散モデルのデノイザの中間層から抽出したクロスアテンションマップを、学習可能な「品質プロンプト」とともに用いることで、画像とテキストプロンプトの整合度に基づく品質表現を生成する。

主なデータセット: ユーザ生成画像、合成歪み画像、低照度画像など、多様な環境の複数ベンチマークで評価。各種データセットを横断するクロスドメイン評価で汎化性を検証した。

貢献: 拡散モデルの潜在機能を活用して一般化性能の高い品質予測を実現。多様なデータセットにわたる徹底的な検証で、他の最先端手法を上回る性能を示し、特に分布シフト下での汎用性の高さを明らかにした。


CONTRIQUE (2022年, Madhusudanaら)

発表年: 2022年 (TIP 2022)

モデル名／著者: CONTRIQUE (P. Madhusudana ら)

アーキテクチャ／技術特徴: CNNベースモデルをコントラスト学習で事前学習し、合成・実写歪み画像が混在したラベルなしデータセット上で学習する手法。歪みの種類と程度を予測する補助タスクを用い、ペアワイズ損失で特徴表現を学習する。事前学習後はCNN重みを固定し、線形回帰器でMOSを予測する。

主なデータセット: KADISなどの大規模合成・実画像歪みデータを用いて自己教師あり事前学習し、その後LIVE、CLIVE、KonIQ-10kなど既存NR-IQAベンチマークで評価。学習には主観スコア不要の大量画像データを用いる。

貢献: 主観スコアなしで品質特徴を獲得し、学習済みCNNを固定のままリニア回帰で良好な性能を示した。多くのベンチマークでSOTA級の精度を達成し、ラベル付きデータが少なくても頑健に機能する汎用表現学習の枠組みを示した。


Align-IQA (2024年, MM’24)

発表年: 2024年 (ACM Multimedia 2024)

モデル名／著者: Align-IQA (匿名査読)

アーキテクチャ／技術特徴: 事前学習済みのViTエンコーダに「品質指向の事前知識」を注入するカスタマイズ可能ガイダンスインジェクターと、マルチスケール特徴を集約するモジュールを組み合わせたフレームワークを提案。ガイダンス注入により、人間の多様な視覚嗜好に沿った品質特徴抽出を促し、マルチスケール集約でより広範な特徴を活用する。

主なデータセット: LIVE、CSIQ、TID2013、KonIQ-10kなどの従来データセットに加え、AI生成画像品質評価用のAGIQA-1K・AGIQA-3Kデータセットでも評価。実画像・合成画像の両方で検証を行った。

貢献: 8種類のIQAベンチマークでSOTA性能を達成した。特にAI生成画像（AIGC）の品質評価では大幅に精度が向上し、AGIQA-1Kおよび3Kで従来比でPLCCが約+3.7%・+2.0%向上した。また、モデルパラメータ数を大幅削減しつつ高い精度を保つ効率的設計を実現している。


参考資料: 各モデルの詳細については引用元をご参照ください。各研究はそれぞれ、NR-IQA分野における新たな枠組みや高性能化をもたらし、後続研究への大きな示唆となっています。



作成日時: 2025-09-25 15:34:48