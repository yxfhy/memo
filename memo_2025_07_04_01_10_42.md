# メモ

DETR系（Transformerベース）

アーキテクチャ概要: DETR (Detection Transformer) はCNNバックボーンの後にTransformerエンコーダ・デコーダを組み合わせ、画像全体から直接オブジェクト集合を予測するエンドツーエンドの物体検出モデルです。出力クエリ数分のバウンディングボックスとクラスラベルを同時予測し、ハンガリアンマッチングによる損失で真のオブジェクトに１対１対応させます。従来検出器で必要だったアンカーやNMS（Non-Maximum Suppression）を使わず、設計されたパイプラインを単一のネットワークで置き換える点が大きな特徴です。

欠陥検出応用例: DETRのエンドツーエンド性は工業製品の欠陥検出にも応用が報告されており、例えば道路舗装のポットホール検出ではDETRを改良したGM-DETRが提案されています。GM-DETRではTransformerにグローバル注意機構（GAM）を加え、デコーダ層の枝刈りや損失関数の変更（L1→MSE）などで学習を高速化・精度向上し、元のDETR比でmAP@0.5が約4.9％改善する結果が得られました。

利点・課題: DETRの利点はグローバルな文脈認識やチューニング不要のシンプルな検出パイプラインにあります。一方、欠点としては学習収束に時間がかかることや小さな欠陥を捉えにくいことが指摘されています。また、トランスフォーマーの計算コストが大きく、実環境でのリアルタイム検出には計算資源の制約が問題となる場合があります。

論文・実装例: DETR論文、MDPI「GM-DETR」（欠陥検出用改良版）などが参照できます。


InternImage-H

アーキテクチャ概要: InternImage はCNNベースの大規模ヴィジョン基盤モデルで、コアに可変畳み込み（Deformable Convolution v3）を用いる点が特徴です。可変畳み込みにより広い有効受容野と入力依存的な空間集約を可能にし、CNN特有の厳密な帰納バイアスを緩和します。これにより、大規模パラメータモデルでも強力な特徴表現が学習でき、COCO物体検出やADE20Kセグメンテーションなどで最先端性能を達成しました。

欠陥検出への応用: 現時点でInternImageを直接欠陥検出に使った報告は見つかっていません。汎用的な物体検出器（例：Mask R-CNNなど）にInternImage-Hをバックボーンとして適用すれば、高解像度かつ広い受容野が有効な欠陥検出に寄与する可能性がありますが、大規模モデルゆえ学習・推論コストが高い点に留意が必要です。

利点・課題: InternImage-H(約10億パラメータ)はCOCOで65.4 mAPを達成し、公開モデルとして世界最高性能を示しました。固定畳み込みカーネルではなく動的フィールドを持つため、多様な欠陥形状に適応しやすいメリットがあります。一方でモデルが巨大なため、大量のデータと計算資源を要するほか、欠陥検出タスクに最適化された研究が進んでいない点が課題です。

論文・実装例: InternImage論文（CVPR2023）、公式GitHub実装（OpenGVLab/InternImage）があります。


M3I Pre-training

概要: M3I（Maximizing Multi-modal Mutual Information）Pre-training はCVPR2023で提案された大規模モデル向けの単一ステージ多モーダル事前学習手法です。画像-テキストや画像-ラベルなど複数の入力と出力（カテゴリ予測・自己教師ありタスクなど）を同時に学習し、相互情報最大化を目的にあらゆる学習シグナルを一括して統合します。従来の教師あり・弱教師あり・自己教師あり事前学習を統一的に一般化し、大規模パラメータモデルが多様なデータソースから利点を引き出せるよう設計されています。

欠陥検出への応用: M3I自体は事前学習手法であり、直接の欠陥検出研究は見当たりません。ただし、M3Iで学習済みの強力なバックボーン（例：InternImage-H）が構築できるため、これを欠陥検出タスクにファインチューニングすれば性能向上が期待できます。今後、産業画像に適したデータ（検査画像とその説明文など）を使ったM3I事前学習が実現すれば、少数サンプルでの高精度検出が可能となる可能性があります。

利点・課題: M3Iでは、InternImage-H (10億パラメータ) を427M画像-テキスト、15M画像-カテゴリデータで事前学習し、COCOで65.4 mAP、LVISで62.5、ADE20Kで62.9 mIoUを達成しました。長大なパイプライン（多モーダルデータ）を単一段階で学習できるため、データ利用効率が高く、汎化性の高い表現が得られます。しかし、その分だけ計算資源と膨大なデータが必要で、実際の工業用画像への適用には追加データの整備や大規模事前学習の実現が課題となります。

論文・実装例: M3I Pre-training論文（CVPR2023）、OpenGVLabによるGitHub実装があります。


MoCaE (Mixture of Calibrated Experts)

アーキテクチャ概要: MoCaEは複数の検出器（エキスパート）のアンサンブル性能を最大化するための手法です。単純な平均（Deep Ensemble）では、信頼度の高いモデルばかりが支配的になり他モデルを活かせない（ミスキャリブレーション）問題があります。そこで各モデルの出力をその信頼度・性能に応じて事前にキャリブレーション（校正）し、キャリブレーション済みの予測同士を組み合わせます。最終的に各エキスパートの得意分野を反映した重み付き結合を実現することで、混合モデルの性能を向上させます。

欠陥検出への応用: MoCaE自体はアンサンブル技法なので、異なるアルゴリズム（例：Faster R-CNNとYOLO、DETR等）の強みを組み合わせる際に有効です。産業検査では、複数の欠陥検出モデルを開発している場合にそれらを組み合わせることで検出精度を高める可能性があります。ただし、現時点で欠陥検出分野での具体的な応用例は報告されていません。

利点・課題: MoCaEはCOCO検出やLVISセグメンテーションで単一モデルに比べ最大約2.5 mAPの改善を示し、COCO test-devで65.1 mAPの最先端性能を達成しています。異なる検出器を組み合わせることで総合性能を底上げできる点が利点です。一方、複数モデルの推論・キャリブレーションが必要なため計算量と実装の煩雑さが増すのが課題です。特にリアルタイム性が求められる場合には複雑になります。

論文・実装例: MoCaE論文およびFiveAIによる公式実装（GitHub: fiveai/MoCaE）があります。


Focal-HuFE（FocalNet系）

アーキテクチャ概要: FocalNetは従来の自己注意機構を「焦点モジュレーション（focal modulation）」と呼ぶ機構で置き換えたニューラルネットワークです。具体的には、まず局所的・広域的な文脈を集約し（Aggregating Context）、それを入力画素に対するモジュレーション係数として適用（Modulating）します。これにより、従来のAttentionの「最初にクエリごとに相互作用、最後に集約」とは逆に「先に集約し後で各特徴に作用」する（FALI）アプローチをとり、計算効率を保ちつつ強力な特徴抽出を可能にしています。特徴間の空間的・チャンネル的関連性を明示的にモジュレーションする点がFocalNetの大きな特徴です。

欠陥検出への応用: FocalNet自体は分類向けに開発されましたが、大型モデル（FocalNet-Huge）をDETR系検出器のバックボーンとして用いる応用が注目されています。例えばStable-DINOではFocalNet-Hugeを組み合わせることで、COCO valで64.6 AP、test-devで64.8 APの高性能を達成しました。欠陥検出においても、大規模なFocalNetを使うことで微細な欠陥や複雑な背景の扱いが向上する可能性がありますが、現時点では文献として報告はありません。

利点・課題: FocalNetは大規模モデルでも計算効率がよく、ImageNet分類やCOCO検出でSOTA水準の性能を実現しています。特に注意機構なしにマルチスケールの文脈を捉えられる点が利点です。一方、モデルサイズが非常に大きく（FocalNet-Hugeで約6.9億パラメータ）学習・推論コストが高い点や、実装が新しいためツールサポートが限られる点が課題です。

論文・実装例: FocalNet論文（NeurIPS2022）、およびStable-DINOでの組み合わせ結果が参考になります。FocalNetの公式実装（GitHub: microsoft/FocalNet）も公開されています。


参考資料: 上記各モデルの原論文や実装ページを引用・参照しています。



作成日時: 2025-07-04 10:08:14