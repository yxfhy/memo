# メモ

ご主人さま、お待たせいたしました。
TabPFN / TabPFNRegressor の仕組みと参考文献をまとめます。


---

1. TabPFN／TabPFNRegressor とは

PFN（Prior-Data Fitted Network） というメタ学習フレームワークで事前学習された “基盤モデル” です。PFN は「大量の人工データセット（＝タスク）を生成し、そのタスクでベイズ推論を行うアルゴリズム自体」を Transformer に埋め込みます。学習は一度だけ離線で行われ、ユーザ側では追加学習をしません。 

推論時は 訓練データをそのまま入力列に並べるだけ で、Transformer が「いま与えられたタスクに対する事後予測分布」を 1 forward で返します。重み更新ゼロなので高速です。 

TabPFNRegressor は 2024 年末に公開された回帰版で、同じコンセプトを回帰損失に合わせて再事前学習したモデルです。初回実行時に数百 MB の重みを自動ダウンロードしたのはそのためです。 



---

2. なぜ LGBM を凌駕し得るのか

1. 小規模データ特化の事前学習

1000 行前後・数十次元程度の数値特徴という設定で膨大なタスクを生成し、ベイズ最適に近い予測器を近似しているため、同規模データでは汎化性能が高く出やすい。



2. モデル構造が固定

ハイパーパラメータ探索が不要で、木モデルよりバリアンスが低い。



3. 全特徴を“文脈”にして同時処理

変数間相互作用や不均衡などを Transformer の自己注意が即座に拾う。



4. ベイズ的分布出力

出力は平均値だけでなく不確実性推定も同時に得られ、スコアリング時の分散低減に寄与。





---

3. どの論文・資料を読むと良いか

用途	推奨リソース	備考

PFN 全体の発想	Meta-Learning to Perform Bayesian Inference in a Single Forward Pass（NeurIPS 2021） 	PFN の元論文、理論背景
TabPFN 分類版	TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second（ICLR 2023） 	TabPFN の実装・実験
TabPFN 回帰版	Prior Labs ドキュメント「TabPFNRegressor」 	API 仕様・制約
最新の総説	Accurate predictions on small data with a tabular foundation model（Nature 2025） 	PFN 系列の現状整理
実装コード	GitHub: PriorLabs/TabPFN 	学習・推論スクリプト



---

4. 使う際の注意点

データ制約: ①数値特徴のみ（カテゴリはエンコーディング要）、②~1 k 行程度、③欠損値は自前で補完。

GPU 推奨: 16 GB 以上が望ましい（CPU でも可だが遅い）。 

外挿は苦手: 訓練分布外の極端値には不確実性が大きく出る。

大規模データ: 1 万行超ではメモリ・計算とも現状厳しい。



---

ご主人さま、以上が概要でございます。さらなる実験設計や論文深掘りが必要でしたら、いつでもお申し付けくださいませ。



作成日時: 2025-07-18 11:20:32