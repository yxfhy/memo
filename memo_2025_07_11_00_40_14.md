# メモ

ご主人さま、機械学習ベースで**高速（リアルタイム志向）**なオプティカルフロー推定を代表する主要論文を年代順にまとめました。すべて 全画素対応（dense flow） を出力するモデルです。

年	論文名 / 略称	主な特徴・推定速度の指標	出典

2015	FlowNet（Dosovitskiy et al., ICCV’15）	CNN だけで光フローを初めて end-to-end 学習。GTX TitanX で 5–10 ms／ペア報告。	
2016	FlowNet 2.0（Ilg et al., CVPR’17）	スタック＋ワーピングで高精度化しつつ 〜140 fps の高速版も提示。	
2017	PWC-Net（Sun et al., CVPR’18）	Pyramid・Warp・CostVolume を組み込み、1024×436 で約 35 fps。小型で実用化が進む。	
2018	LiteFlowNet / LiteFlowNet2（Hui et al., TPAMI’20）	コスト体積を極小化した軽量 CNN。GTX1080 で ≈ 40 ms（1024×436）と報告。	
2020	RAFT（Teed & Deng, ECCV’20）	全画素相互相関＋GRU 反復。高精度ながら RAFT-Small は ～20 fps 実装例多数。	
2020	ARFlow（Liu et al., CVPR’20）	「類推学習」により教師なしで高精度。PWC-Lite 系統で モバイル GPU 実時間 を狙う。	
2021	GMA（Jiang et al., ICCV’21）	RAFT を基盤に Global Motion Aggregation で大変位を高速推定、RAFT より速い。	
2021	LoFTR-Flow 系（研究派生）	Transformer で全画素マッチング → 準フロー生成。EfficientLoFTR で 30 fps デモ有。	（LoFTR 系速度報告）
2022	GMFlow（Xu et al., CVPR’22）	4D 相関を 1 回のグローバルマッチングで推定し、RAFT‐31 step より高速。	
2022	FlowFormer / FlowFormer++（Huang et al., ECCV’22, CVPR’23）	AGT Transformer でコストボリュームをトークン化。高速化版でリアルタイム実装が進行中。	


> 補足

FlowNet / FlowNet2 以外は公式コードで TensorRT/ONNX 最適化すると 10〜50 ms に収まるケースが多く、印刷スキャン位置合わせに十分な速度が得られます。

産業機へ組み込む際は LiteFlowNet 系・RAFT-Small 系が GPU メモリ 2 GB 前後で動くため採用例が多いです。




以上が高速オプティカルフローの代表的論文でございます。



作成日時: 2025-07-11 09:40:11