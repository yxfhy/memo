# SPAQ属性回帰研究の現状整理

ご主人さま、確認しました。結論：ご指摘どおり、SPAQ の「5属性（Brightness/Colorfulness/Contrast/Noisiness/Sharpness）」を “属性ごとに回帰してレポートまでしている” 研究は少数です。 多くのBIQA論文は SPAQ をMOS専用（単一スコア回帰）として使っています。

主要な「属性を使う／出す」代表例（少数）

SPAQ原著（CVPR 2020）：データとして5属性を整備し、多タスクのベースライン（MOS＋5属性）も提示。以後の研究で属性定義のリファレンスになっています。

MDIQA（2025）：技術系5属性（SPAQの5属性）＋美的4属性のマルチヘッド回帰。学習にSPAQの多次元注釈を使うことを明記。

MaC-BIQA（ISCAS 2025）：属性ごとの継続学習フレーム。SPAQ/KonIQ-10Kで、多属性タスクを忘却なく学習することを狙う（属性を明示的に扱う稀な例）。

SARQUE（TMM 2022）：5つの意味属性（brightness, colorfulness, contrast, noisiness, sharpness）を同時予測し、シーンとの関係をGCNで推論する“説明可能BIQA”。（SPAQ属性と同名の属性を明示的に回帰）

ATTIQA（ACCV 2024）／CLIP指向の属性事前学習：5代表属性を用いた属性アウェア事前学習で汎化性を高める流れ（属性は補助監督として活用されるが、最終タスクはMOS中心）。


なぜ少ないのか（観測）

1. 属性アノテーションの希少性：SPAQ以外で同等粒度の属性GTが乏しい（SPAQは5属性を明確化）。そのため、MOS単独での学習に流れやすい。


2. 評価慣行がMOS中心：ベンチマークや大会はSRCC/PLCCのMOS相関で競うことが多く、属性指標の公式評価プロトコルが限定的。MDIQAも最終的にMOSを出すが、途中で属性を出せるのが価値という位置付け。


3. 属性定義の非互換：データセット間で属性定義が合わず、継続学習等の工夫（MaC-BIQA）が必要になる。



補足（参考になる周辺の動き）

MDIQA系：多属性をヘッドごとに出力し、適応重みで統合。SPAQの5属性を技術系の基礎軸として使う代表格。

意味属性×説明可能BIQA（SARQUE）：属性分布を出力してなぜ悪いかを説明。SPAQの語彙に揃っている点が現場で扱いやすい。

属性を前処理に使う研究：ATTIQA/CLIP誘導など、属性を擬似ラベルや事前学習に使って汎化を狙う流れ（最終出力はMOSが多い）。



---

要するに：SPAQの5属性を“そのままGTとして学習・出力”するのは、SPAQ原著のベースライン、MDIQA、MaC-BIQA、SARQUEなど少数派です。多くのBIQAはMOSのみを使い、属性は補助（前処理・事前学習）として触れるに留まるケースが多い、という確認結果でした。



作成日時: 2025-09-16 11:36:49