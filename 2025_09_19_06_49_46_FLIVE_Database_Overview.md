# 最大規模UGC画像品質データFLIVE解説

はい、ご主人さま。FLIVE（しばしば “FLIVE” と略称されますが、原論文では LIVE-FB Large-Scale Social Picture Quality Database と呼ばれます）の要点を長めに、整理してお届けします。

概要（正体・規模・位置づけ）

正式名：LIVE-FB Large-Scale Social Picture Quality Database（通称 FLIVE）
2020年のCVPR論文 From Patches to Pictures (PaQ-2-PiQ) で導入された、大規模な“実環境（UGC）”写真の主観画質データセットです。

規模：39,810枚の写真と119,430枚のパッチに対し、約400万件の人手評価（写真≈100万、パッチ≈300万）を収集。被験者は7,865人。IQA分野の“in-the-wild”系では当時最大規模で、その後の研究でも最大級の基準として扱われています。

用途の広がり：NR-IQA（参照なし画質評価）の事前学習・大規模検証に広く使われ、近年の手法（例：品質認識型プレトレーニングや対比学習系、VLM系IQAなど）の評価項目に定着しています。


収集設計（UGCらしさの担保）

データ源の作り方：AVA、VOC、EMOTIC、Blur Detection などの公開画像群から約4万枚をサンプリング。画素数・輝度・色鮮やかさ・RMSコントラスト・SI（Sobel勾配の分散）・顔検出数といった客観特徴のヒストグラムが、Facebook内でランダム抽出した1,500万枚のUGCと近づくよう混合整数計画で選別。ダウンサンプリングを行わず、多様な解像度・アスペクト比をそのまま保持しています。

パッチ生成：各写真から3枚のパッチ（元画像の20%／30%／40%の線寸）を、**最大重なり25%**までの制約でランダム切り出し。ローカル品質とグローバル品質の関係学習を意図した設計です。


主観評価プロトコル（品質管理込み）

プラットフォーム：Amazon Mechanical Turk（AMT）。N=60から始め、安定性確認後N=210に拡大して一度のHITで評価。

品質管理：
受注者の承認率閾値（>75%）、重複提示による一貫性チェック、**ラボで18名が評価した“ゴールド画像/パッチ”**を混ぜての監査などを実施。

指標：MOS（平均意見スコア）を基本に分析。FLIVEのMOS分布はCLIVEやKonIQ-10kと比べ尖りが強く、微小な品質差の識別が重要になる“現実的で難しい”タスクになることが示されています。写真と大きいパッチ（40%）のMOS相関はLCC≈0.43。


公式分割と前処理（論文準拠の学習設定）

公式スプリット：写真約30k/7.7k/1.8k（学習/検証/テスト）。一辺が640pxを超える写真はテストへ送るというルールを含み、学習・検証では640×640の白縁パディングでサイズを揃えています（“中身を変えない”という心理計測上の配慮）。この設定を後続研究も踏襲するケースが多いです。

評価指標の慣例：SRCC/PLCC（LCC）を報告。原論文では学習を写真に対して行い、パッチでも評価を出して比較しています。


FLIVEの“らしさ”（CLIVE/KonIQ-10k/SPAQとの違い）

実環境の複合歪み：撮影・処理・圧縮などが混在するAuthentic Distortionで、合成単一歪み中心の“レガシー系”とは性質が異なる。CLIVE（1,162枚）、KonIQ-10k（約1万枚）、SPAQ（11,125枚・スマホ写真）よりも枚数・評価数が大きく、解像度/比率の多様性も強い点が特徴です。

分布の難しさ：UGCの性質上、極端に悪い/良いより“そこそこ良い”が多く、微差の弁別を学習できるモデル設計・損失設計が重要になります。


取得・配布（どこで手に入るか）

入口：UT Austin・LIVE研究室のデータベース一覧から**LIVE-FB（FLIVE）**に到達できます（GitHubに誘導）。

内容物：GitHub（niu-haoran/FLIVE_Database）では、画像そのものではなく、ラベルCSV（例：labels_image.csv / all_patches.csv）や取得スクリプトを提供。元画像は出自（AVA等）の配布規約に従って各ソースから取得する方式です。


研究での使われ方（代表的トピック）

大規模事前学習の土台：品質認識型プレトレや対比学習系IQAで**“最大のin-the-wild静止画IQAデータ”として学習・評価の基準面**を支えています。

スプリット準拠の表記：多くの論文が「FLIVEは著者推奨スプリットに従う」と明示して再現性を担保しています（他データセットはランダム分割のことも多い）。

ローカル品質の活用：パッチのラベルが整備されているため、品質マップや局所→全体の推論設計（PaQ-2-PiQの発想）に発展しやすいです。


注意点（実務で扱う際の勘所）

配布形態：画像が一括配布されるデータセットではないため、CSVに従い元データを取得する手間がある（ライセンス上の配慮）。

前処理の差：原論文の白縁640を守るか、独自のリサイズ/パディングにするかでスコアが変わりうる。報告時は前処理とスプリットを明記するのが無難です。

分布の偏り：UGC準拠ゆえ、難度が“微差識別”寄りになりやすい。CLIVE/KonIQ/SPAQとのクロス評価で挙動を確認するのが一般的です。



---

参考（一次情報・入手口）

PaQ-2-PiQ 論文（CVPR 2020）：データ設計・収集・分割・前処理の一次情報。

LIVE 研究室の配布ページ（LIVE-FBへの導線あり）。

FLIVE GitHub（ラベルCSVとスクリプト）。

近年のIQA論文での位置づけ（“最大規模のin-the-wild静止画IQA”としての記述）。


ご所望でしたら、同じ“UGC系”の CLIVE / KonIQ-10k / SPAQ との比較表（規模・評価法・前処理慣行・推奨スプリット）も作成できます。



作成日時: 2025-09-19 15:49:41