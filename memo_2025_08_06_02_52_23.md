# メモ

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch, readline  # readline は矢印キー履歴用（Unix 系）

model_id = "abeja/gpt2-large-japanese"
tok = AutoTokenizer.from_pretrained(model_id, use_fast=False)
model = AutoModelForCausalLM.from_pretrained(model_id, device_map="auto")

history = []
while True:
    user = input("👤 > ")
    if user.strip() in {"exit", "quit"}: break
    prompt = build_prompt(history, user)
    input_ids = tok.encode(prompt, return_tensors="pt").to(model.device)
    gen_ids = model.generate(
        input_ids,
        max_new_tokens=128,
        temperature=0.8,
        top_p=0.95,
        repetition_penalty=1.2,
        pad_token_id=tok.eos_token_id,
    )
    answer = tok.decode(gen_ids[0][input_ids.shape[-1]:], skip_special_tokens=True)
    print("🤖 >", answer.strip())
    history.append((user, answer.strip()))
    # コンテキスト長管理
    if len(tok.encode(build_prompt(history, ""))) > 1024:
        history = history[-5:]  # 直近5往復だけ残す

作成日時: 2025-08-06 11:52:22