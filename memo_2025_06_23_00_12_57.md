# メモ

少数ショット学習とデータ拡張

少数サンプル環境では、転移学習（事前学習済みモデルの微調整）やメタ学習（MAML等）を用いて少量データから迅速に適応する手法が有効とされている。また、メトリック学習（ProtoNetなど）も学習データを距離学習により拡張し、少数例でも特徴抽出の性能向上に寄与する。さらに、生成モデル（GAN/VAEや拡散モデル）を使ってデータを人工的に増やし、データ拡張する研究も進んでいる。例えば拡散モデルを活用したAnomalyDiffusion (2024) は，少ない正常画像から異常画像を生成して検知器を訓練する。最近の手法では、大規模視覚言語モデル（CLIP等）を利用した高速適応も注目される。たとえばProto-Adapter (2024) はCLIPに対しプロトタイプベースのアダプタを導入し、少数ショット設定で既存のCLIP改良手法を上回る性能を示している。また、VisionAD (2025) は1正例のみを用いるワンショット異常検知手法で，CLIP特徴マッチングを用いて高精度を達成している。同様に、FLIER (2024) ではGPT-3とStable Diffusionで画像と対応埋め込みを生成し、CLIPの性能を強化してFew-shot分類のSOTAを報告している。これらによって、少数データでも高い認識性能が得られている。

難易度の高い画素／画像への重み付け・キャリブレーション

画素レベルでは、損失関数の重み付け（クラス重み付き交差エントロピーやフォーカルロス）で少数クラスや難事例の影響度を高める手法が一般的である。例えばクラス不均衡問題では、過サンプリングやコストセンシティブ学習でマイノリティクラスの損失を増加させる対策が提案されている。分類器のキャリブレーション（温度スケーリングや学習率調整）も信頼度の調整に有効である。最近の研究では、ピクセル埋め込み自体を改良するアプローチもある。RWPM (2024) は画素埋め込み間の関係性をランダムウォークで拡散させ、埋め込みの歪みを抑えて異常スコアの精度を向上させた。CostFilter-AD (2025) はマッチングコスト行列をフィルタリングしてノイズを除去し、微細な異常検出精度を高める手法である。これらにより難しい画素の識別が改善し、セグメンテーション精度が上がっている。

マルチモーダル・LLM活用

画像とテキストを同時に扱う視覚言語モデルを用いたアプローチが急速に普及している。CLIPなどのモデルにテキストプロンプトを与えることで、少数ショット異常検出や分類が可能だ。たとえば、WinCLIP (2023) はCLIPに多数の状態語プロンプトを組み合わせ、言語誘導により異常検知性能を大幅向上させた。AnomalyCLIP (ICLR2024) では「正常／異常」を表すオブジェクト非依存のプロンプトを学習し、多様な物体の異常をゼロショットで検出した。PromptAD (CVPR2024) は正常例のみからプロンプトを学習し、明示的異常マージン制御でプロンプト特徴を分離、少数ショットでSOTA性能を達成している。また、画像キャプション生成などで得たテキスト情報を活用する例も増えている。さらに大規模言語モデル（LLM）を組み込んだ手法も登場した。AnomalyGPT (AAAI2024) はMiniGPT-4等のLVLMに対し、異常を模擬した視覚テキストデータでファインチューニングし、閾値不要で異常の有無と位置を推定する対話型システムを実現した。これらにより、画像理解に言語の意味付けや推論を組み込んだアプローチが可能となり、少数データ下でも高い検出精度が報告されている。

最近の異常検知技術動向

異常検知分野では、教師なし学習や自己教師あり学習の手法が数多く提案されている。古典的にはオートエンコーダやGANで正常分布を学習し、再構成誤差で異常を検出する方法が主流だった。近年は拡散モデルの利用も活発で、データへのノイズ付加・除去過程で得られる尤度や誤差で異常を検出する手法が登場している。また、近年はテクスチャ合成やデータ補完によるデータ拡張も研究されており、例として拡散モデルによる異常合成で少数ショット性能を向上させた事例がある。一方で、領域ベースの手法や確率モデルを用いる傾向も強い。CostFilter-AD (2025) は事前学習済み特徴のコストボリュームからノイズを取り除くことで、産業異常検知精度を改善している。GASN (2025) はGANで多数派（正常）分布に類似した合成データを生成し、元データとの類似度から微細な異常を検出する2段階手法を提案し、既存手法よりAUCが約10%向上した。これらにより定性的・定量的に異なるアプローチで新種の異常を検出する研究が進んでいる。

クラス不均衡対策

クラス不均衡への対応では、データレベルとアルゴリズムレベルの両面で多くの手法がある。データレベルでは、マイノリティクラスの過サンプリングやマジョリティのアンダーサンプリングにより学習サンプルの偏りを緩和する。アルゴリズムレベルでは、損失関数にクラス重みを掛けるコストセンシティブ学習が一般的であり、フォーカルロスやクラスバランス損失などが用いられる。例えばLDAM-LossやCuiらの「有効サンプル数」に基づくクラスバランス損失は、少数クラスに対するマージンを大きくして性能向上に寄与する。また、後続学習で表現学習と分類器学習を分離するde-coupled trainingや自己教師あり学習による平衡表現の獲得なども研究されている。これらの手法により、サンプル数の偏りが大きい環境でも少数クラスや難易度の高い例に対するモデル性能を高めている。

アプローチ	代表的手法例	特長／効果	参考・実績 (実装)

少数ショット学習	転移学習／メタラーニングProtoNet, Proto-Adapter	少量データから効率的に学習可能。Proto-AdapterはCLIPベースで高精度。	[Kato2024] (公式実装参照)
生成的拡張	GAN, VAE, 拡散モデルAnomalyDiffusion	正常・異常データを人工生成。少数例でのモデル訓練に寄与。AnomalyDiffusionで高品質異常生成。	[Hu2024] (コードあり)
領域・重み付け	フォーカルロス, 重み付きCERWPM	少数クラスや難所の損失を増大。RWPMは画素埋め込みを平滑化しセグ精度↑。	[Zeng2024] (GitHub実装)
マルチモーダル/LLM	CLIPプロンプト（WinCLIP, AnomalyCLIP）PromptAD, AnomalyGPT	テキスト情報で視覚概念を強調。PromptADは正常のみプロンプト学習でSOTA。AnomalyGPTは会話型LLMで異常検知。	[Jeong2023], [Gu2023] (コードあり)
異常検知（教師無/自己)	自己教師ありAE/GAN, 正常モデリングCostFilter, GASN	異常なしデータのみで正常モデルを構築。CostFilterでマッチングノイズ除去、GASNでGAN合成による感度向上。	[Liu2025], [Chen2025]
不均衡対応	オーバー/アンダーサンプリングコストセンシティブ学習	マイノリティの比重を増すことでモデルのバイアスを緩和。クラス重み付き損失やfocal lossで少数クラス識別率向上。	[Hojjati2024] (総説より)


参考文献: 最新論文や総説より引用など。各手法の詳細は上記文献・実装を参照。



作成日時: 2025-06-23 09:12:56