# メモ

ご主人さま、かしこまりました。
まず RAFT と PWC-Net それぞれの「基本アルゴリズム像」を整理し、ご主人さまのお考えを確認・補足いたします。そのうえで、アルゴリズム構造に起因する本質的な違いを示します。


---

1  RAFT と PWC-Net の基礎構造

観点	RAFT	PWC-Net

全体フローの求め方	① 特徴抽出（単一解像度）② 全画素相互相関で 4-D コスト体積を一度だけ作成（画像全域のペアを保持）③ 再帰的 GRU でフローを T 回更新（粗→微へ連続的に収束）	① ピラミッド特徴抽出（低→高解像度）② 各階層で「Warp → コスト体積作成 → CNN 推定」を実行し残差フローを出力③ 上位解像度へアップサンプルして再び同処理
「順次精度向上」の意味	同一解像度 上で GRU が残差フローを繰り返し洗練（時系列的 refine）	異なる解像度階層 を上がりながら残差フローを refine（空間的 coarse-to-fine）
大きな視差の扱い	全画素相関を持つので 1 回目から大視差が候補に含まれる。更新は局所(9×9)だが初期対応がすでに全局的	最下層（荒い解像度）で小さな視差に縮小した状態から推定し、階層を上がるごとに視差を細かく補正
計算・メモリ	相関体積が W×H×W×H 規模 → VRAM と MACs 多。ただし相関は固定で再利用できる	階層ごとに小さな相関体積を都度生成 → 軽量。ただし階層ループぶん演算回数は多め
誤差伝搬の性質	逐次 GRU 更新なので誤差が自己補正しやすく、階層間の蓄積誤差なし	低解像度層で生じた誤差が上位層に 持ち上がりやすい（いわゆる coarse-to-fine drift）


> ご主人さまのお考え
「RAFT は順次精度向上、PWC はピラミッドで解像度向上」
→ 方向性は正しく、上表のように “順次” の対象が 時間的反復(RAFT) と 解像度階層(PWC) で異なる点だけ補足いただければ完璧です。




---

2  本質的な違いと、その帰結

視点	RAFT 系ゆえの性質	PWC-Net 系ゆえの性質

精度・細部	1 枚目から全局的候補を保持→誤対応を後の GRU で修正可能。微細テクスチャや薄い線でも最後まで情報が残り、サブピクセル精度が高い。	coarse-to-fine で誤対応ごと拡大する危険。細線・薄文字など 微細パターンは失いやすい。
大視差・回転	全画素相関があるので 一気に拾える。反復回数は増えるが理論上視差上限なし。	ピラミッドで視差を縮小できる範囲に依存。極端に大きい視差や回転があると最下層でも一致せず失敗し得る。
計算・メモリ効率	相関体積がボトルネック。最新軽量派生（SEA-RAFT など）は 相関埋め込み削減で VRAM↓だが、根本的に重め。	階層ごとに限定相関を生成するため メモリ小。演算は階層ループで増えるが並列化しやすく、組込み実装が容易。
拡張のしやすさ	GRU 更新層を差し替えて物理拘束・マスク推定など追加しやすい。例: GMA, MaskRAFT	ピラミッド構造を崩さずに拡張する場合、多層全てに変更が波及しやすい。
ハードウェア適応	GPU では高速化余地大 (相関は行列演算で最適化可)。FPGA/CPU 単体だと負荷大きい。	相関体積が小さいので FPGA/CPU でも動かしやすい。スマホ SoC 実装例も豊富。



---

まとめ

アルゴリズム本質の差は
RAFT: “単一解像度で反復洗練”
PWC: “多解像度で階層洗練”。
これが誤差伝搬の挙動・メモリ負荷・大視差対応力の違いを生みます。

速度面は派生研究で互いに追いつきつつありますが、
精度とメモリのトレードオフは上記構造差に由来するため完全一致には至りません。


ご主人さまのご参考になれば幸いです。さらに深掘りや実装選定のご相談があれば、いつでもお申し付けくださいませ。



作成日時: 2025-07-15 09:16:14