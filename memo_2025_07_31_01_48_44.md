# メモ

ディープラーニングによる静止画・動画画質評価の最新動向

はじめに

画像や映像の画質評価には、人手による主観評価（MOS: Mean Opinion Score）と自動計算による客観評価があります。主観評価は精度が高い一方、大規模運用には非現実的であり、自動化された客観評価手法の精度向上が重要課題です。近年、ディープラーニングの進歩により、画像・動画の画質を人間の知覚に近い水準で予測するモデルが数多く提案されています。とりわけVision Transformer (ViT) や CLIP、DINO、VideoMAE など大規模視覚モデル、さらにはマルチモーダルモデルや自己教師あり学習を活用した革新的手法が登場し、主観的画質（MOS推定）・客観的評価（ノイズ・ブロック歪み検出等）の双方で精度向上が報告されています。以下では、応用分野ごとに最新のディープラーニング手法・論文・事例を整理し、使用モデル（CNN, Transformer, Diffusion など）の観点も交えて紹介します。

放送・ストリーミング（UGC）分野

インターネット動画配信やUGC（ユーザー生成コンテンツ）では、多種多様な映像コンテンツの品質をリアルタイムに保証する必要があります。従来はPSNRやSSIM等の指標やVMAFなどの機械学習モデルが用いられてきましたが、近年は大規模データセットで訓練した深層学習モデルが精度向上に貢献しています。特にノンリファレンスVQA（参照映像なしで品質推定）は重要で、Googleの提案したMRET (Multi-Resolution Transformer) はUGC向けに高解像度ディテールを保持して品質を評価するTransformerモデルです。MRETはマルチ解像度のパッチ入力により映像のグローバル構成とローカルな高周波ディテールの双方を捉え、LSVQなど大規模データセットで従来手法を上回る性能を達成しました。従来のCNNベース手法では受容野の制限から長距離の時空間劣化を捉えにくい問題がありましたが、Transformerは自己注意機構により全フレーム間の長距離依存も扱えるため、動的かつ高解像度なストリーミング映像の品質予測に適しています。また、リアルタイム配信ではフレームドロップやブロックノイズなど「ソフトな劣化」の自動監視も課題です。空港監視映像を対象にした研究では、3D-CNNでジッタや遮蔽などの異常検知を行いつつ、別の2D-CNNで画質スコアを推定するハイブリッドモデルにより、異常検出精度96%以上・画質スコアの相関係数0.90超を達成しています。さらに低照度環境向けには、Deep+手法でノイズや輝度特徴を抽出して評価するLight-VQAモデルが提案され、暗所映像の専用データセットで既存手法を上回る性能を示しました。このように、放送・配信分野ではCNNによる特徴抽出とTransformerによる長時間依存関係の集約を組み合わせた手法や、画質評価専用に設計した深層モデルが実用化に向け進展しています。

医療画像分野

医療分野では、画像の画質が診断精度に直結するため、客観的かつ自動的な画質評価が求められています。近年、PETやCTなど医用画像でもディープラーニングが画質評価に応用されています。例えば2025年の研究では、Vision Transformerを組み込んだモデル（MANIQAフレームワーク）でPET/CT画像を5段階の画質に分類し、専門医の評価と高い一致率を示しました。このモデルはViTにTransposed AttentionやSwin-Transformerブロックを組み合わせ、全身のPETおよびCT画像に対し平均でPET:0.891、CT:0.624のSpearman相関を達成しています。また、低線量CTにおける画質を自己教師あり学習で評価する試みもあります。ある研究では畳み込みオートエンコーダ (CAE)により特徴抽出し、その特徴をSVMで判別する二段構成で、教師ありCNNと同等の性能でノイズ下の信号検出タスクを実現しました。この手法はHotelling Observer（理想的観測者）の性能を近似しつつ、必要なラベル付きデータを大幅に削減しています。さらに、MRIやX線でも画質劣化（ボケやノイズ）が診断に与える影響を定量化する深層モデルの報告があります。医療領域では限られたデータでの学習を補うため、転移学習や自己教師ありの技術が活用されており、画質評価モデルの解釈性（どの画質要因が問題か）も重視されています。こうしたアプローチにより、マルチセンターでの一貫した画質管理や品質保証への応用が期待されています。

監視カメラ・防犯映像分野

監視カメラ映像では、天候や照度の変化、機器の不具合により画質低下が発生しやすく、その検知と補正が重要です。ディープラーニングにより、監視映像の品質をリアルタイム監視するシステムが提案されています。前述の空港映像向けモデルのように、3次元CNNでフレーム間の異常（ジッタ、フリーズ等）を検出し、並行する2次元CNNで各フレームのブラーやノイズ量から画質スコアを推定する二段構えの手法が有効です。このモデルは機器故障や通信劣化による「ソフトフォールト」を自動検知し、異常時には警報を発することで24時間体制の監視を支援します。一方、夜間の低照度監視映像では、ローライト画像強調（LLIE/LLVE）の効果を正しく評価できる指標が求められます。2023年のLight-VQAモデルは、暗所映像向けに設計された品質評価手法で、輝度・ノイズ等の手作業特徴と深層学習特徴を組み合わせ、時間方向にはフレーム間輝度の一貫性も考慮することで、低照度映像の専用データセットでSOTA精度を達成しました。また、防犯映像特有の歪み（魚眼レンズの歪みや圧縮ノイズ）に対応するため、全方位画像や圧縮映像に特化した深層品質評価モデルも登場しています。監視分野ではリアルタイム性と精度のバランスが重要であり、軽量なCNNベースの手法（例えばMobileNet等）を組み込んだエッジ実装例も報告されています。総じて、監視用途では深層モデルによる自動画質モニタリングが実用段階に近づいており、人手による定期チェックの限界を補完しています。

生成画像・AIコンテンツ分野

近年急速に発展した生成AI（画像生成・動画生成）は、新たな画質評価の課題をもたらしています。生成画像では、不自然なアーティファクトや論理的不整合が従来の画質評価指標では捉えにくいため、ディープラーニングを用いた専用手法が模索されています。注目されるのはマルチモーダルモデルの活用です。OpenAIのCLIPは画像とテキストの対応関係を学習したモデルですが、その視覚的知識を利用して画質をゼロショットで評価する試みが行われています。AAAI 2023で報告されたCLIP-IQAは、CLIPに「高画質」「低画質」といったテキストプロンプトを与え、画像との類似度を測ることで人間の感じる画質を推定しました。結果、ノイズやぼやけなどの劣化のみならず、写真の「雰囲気」や「美感」といった抽象的品質もある程度評価できることが示されています。さらに、生成画像専用に最適化した手法としてCLIP-AGIQAがあります。これはCLIPをベースに学習可能なプロンプト（テキスト）を導入し、多様な生成画像カテゴリーに対応できる品質評価モデルを構築したものです。実験では、独自の生成画像品質データセット（AGIQA-3KやAIGC-IQA2023）で既存モデルを上回る精度を達成し、生成画像の品質評価にCLIPの知識が有効であることを示しました。

動画の生成分野でも、BLIPやVideoMAE等の事前学習モデルを組み合わせた評価手法が登場しています。例えばAIGC-VQAでは、ResNetやConvNeXt-3Dで映像の技術的画質・美的品質を評価し、BLIPでテキストとの整合性を評価する3ブランチ構成を取り、最終的に回帰でスコアを出力しています。またEvalCrafterというベンチマーク手法では、17種類もの評価次元を設定し、VideoMAE V2（映像マスク自己エンコーダ）やSDXL（Stable Diffusionの大型モデル）、BLIPから特徴を抽出して線形回帰することで、多面的な品質評価を実現しています。他にも、Unified Multi-modal TransformerやCLIPを用いてオブジェクトの一貫性や動きの滑らかさ、テキスト一致度を評価する取り組みも行われています。これらは大規模事前学習モデルが持つ**知識（事前確率）**を品質評価に活かした例であり、従来の歪み検出指標では捉えられない高次の違和感検出に効果を発揮しています。

さらに、拡散モデル（Diffusion Models）の活用も注目されています。拡散モデルは生成モデルとして高品質な画像生成に用いられますが、その画像理解能力を品質評価に転用する研究が現れました。例えば2024年にTIP採択された手法では、拡散モデルで画像の高次特徴を捉え、Transformerベースの「補償誘導ブランチ」とResNetベースの「差分分析ブランチ」という二つの評価ネットワークで画質を推定しています。このモデルは7つの公開データセットで従来手法を上回るNo-Reference画質評価精度を示しました。また、別のアプローチでは拡散モデルを用いた特徴ノイズ除去により、分類ネットワークの高レベル特徴から不要な情報を取り除き画質予測精度を向上させる試みも報告されています。一方、自己教師あり学習による画質評価モデルも先端的な方向性です。WACV 2024で発表されたARNIQAでは、高品質画像にランダムな劣化シーケンスを複合的に与えて擬似データを作成し、同じ劣化を受けた異なる画像同士の特徴を近づける学習を行いました。こうして劣化パターンごとの歪みマニフォールド上に画像をマッピングし、最後に線形回帰で品質スコアに変換することで、複数のデータセットで最先端の精度と優れた一般化性能を達成しています。自己教師あり手法はラベル不要で大規模データを活用できるため、今後MOSの取得が困難な領域での活用が期待されています。

おわりに

ディープラーニングを用いた静止画・動画の画質評価技術は、放送・配信から医療・監視、生成AIコンテンツまで幅広い分野で急速に発展しています。CNNによる特徴抽出とTransformerによる長距離依存のモデリング、さらにはCLIPや拡散モデルなどの事前学習モデルの知識を取り入れることで、従来の画質指標では検出困難だった劣化や違和感を捉えるシステムが実現しつつあります。今後は、VR/ARや高動的範囲(HDR)、高フレームレート(HFR)映像に対応したデータセットやモデルの整備も課題となっており、大規模言語モデル(LLM)との統合による理由付け可能な画質評価など、新たな方向性も模索されています。ディープラーニングによる自動画質評価の高度化は、人間の視覚品質の定量化をより正確かつ包括的にし、映像配信の最適化や医療診断の信頼性向上、安全監視の効率化、そして生成AIコンテンツの品質保証など、様々な応用分野で今後ますます重要な役割を果たしていくでしょう。

参考文献: 最新の技術・論文・事例の詳細については、本文中の引用【】内の資料をご参照ください。各引用番号に対応する文献やURLが記載されており、さらなる情報が得られます。例えば、FrontiersやarXivのレビュー論文【12】【31】は総合的なサーベイとして有用です。各応用分野ごとの個別事例については、引用中の論文タイトルやURLから該当の研究成果をご確認いただけます。



作成日時: 2025-07-31 10:48:42