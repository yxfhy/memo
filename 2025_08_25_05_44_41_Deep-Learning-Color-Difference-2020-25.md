# 深層学習による色差評価の最前線

深層学習による色差評価指標の進化（2020年～2025年）

2020年: 深層学習型知覚指標の台頭と色差評価への着目

深層知覚評価指標の登場 – 2018年頃からLPIPS（Zhangら）やPieAPP（Prashnaniら）およびDISTS（Dingら）など，畳み込みニューラルネットワークを用いた画像の知覚的類似度評価手法が登場しました。これらの手法は従来の手作り指標と比べて深層特徴の有効性を示し、2020年前後には画像の知覚品質評価で広く注目されました。

色差評価への応用 – 上記の汎用深層指標は色の違いも含めた画像全体の差異を学習したもので、CIELABやCIEDE2000など伝統的な色差式とは異なるアプローチです。色差評価分野では2020年前後、このような深層学習による知覚指標を画像上の色違い評価に適用しようとする動きが始まりました。しかしLPIPSやDISTSといった既存モデルをそのまま色差判定に使った場合、訓練データの性質や構造重視の特徴により人間の色差知覚との高い一致性能には達しないことが報告されています。このため、より色差評価に特化した深層学習モデルの必要性が認識され始めました。


2022年: 大規模色差データセット「SPCD」の構築

SPCDデータセットの公開 – 香港城市大学（CityU）・南昌大学などの研究チーム（Keshuo Xu、Zhihua Wang、Kede Maら）は、スマートフォン写真における視覚的色差の大規模データベース SPCD（Smartphone Photograph Color Difference）を構築しました。このデータセットには15,335枚の実写画像とそこから作成された30,000組の画像ペアが含まれ、人間による色差知覚スコアを大規模な主観実験で取得しています。従来は均一色パッチで測定された色差データが主流でしたが、SPCDは複雑な自然画像での色差評価に踏み込んだ初の大規模データとなりました。これにより、深層学習に十分な教師データが初めて整い、写真画像上での色差評価式を学習によって最適化する道が開かれました。


2023年: 深層学習型色差式「CD-Net」の提案

CD-Net（Wangら, 香港城市大学） – Wang Zhihuaらの研究グループは、上記SPCDデータを用いて初のエンドツーエンド学習型色差評価式「CD-Net」を提案しました。CD-Netは軽量なCNNベースのネットワークによってカラー空間変換を学習し、その変換空間上でユークリッド距離を計算することで色差（ΔE）を予測します。従来の複数の色差式を包含・拡張する形で設計されており、33種類の既存色差指標を大きく上回る精度を達成しました。またCD-Netで学習されたカラー空間は人間の知覚により近い「擬似一様色空間」となっており、画像内の局所的な色差マップも教師なしで合理的に推定できることが示されています。この研究により、深層学習によって写真画像専用の色差指標を構築できることが初めて実証されました。さらにCD-Netは均一色パッチデータにも良好に一般化し、数学的な距離の公理も満たすことが報告されています。

CD-Flow（Chenら, 香港城市大学） – 同じくMa教授のチームのChen Haoyuらは、2023年のCVPRにてCD-Flowと呼ばれる新たな色差評価モデルを発表しました。CD-FlowはCD-Netを発展させたもので、正規化フロー（normalizing flow）による可逆的なカラー特徴変換を導入した点が特徴です。6段階の多スケールフロー変換で画像の色・形状情報を抽出し、変換後の特徴空間でユークリッド距離を算出することで色差を得ます。この可逆変換により**数学的な全単射性（可逆性）が保証され、変換空間での距離が元の色差に比例するよう最適化されています。CD-FlowはSPCDデータで学習・評価され、15種類以上の既存指標を凌ぐ性能と報告されました。特にCD-Netを含む他手法に比べ統計的指標で最高の相関を示し、幾何的なずれに対する頑健性も向上しています。研究陣は「色と形は不可分である」**という最新の視覚科学知見を踏まえ、粗視的な特徴に重み付けしたフロー設計が有効だったと述べています。CD-Flowの提案により、深層学習による色差評価はさらなる精度向上と視覚的整合性を実現しました。


2024年: CD-iNetによる色差評価の高度化

CD-iNet（Wangら, IJCV 2024） – Wang Zhihuaらはさらに発展版としてCD-iNet（Color Difference Invertible Network）を国際コンピュータビジョン誌で発表しました。CD-iNetは可逆な深層写像（DINN: Deep Invertible Neural Network）を用いて色空間変換を学習し、その空間でピクセル単位のユークリッド距離を平均することで画像間色差を計算します。特筆すべきは、従来のCIE標準式の設計思想（知覚的に一様な色空間）を取り入れつつ、均一色パッチの古典データとSPCDの画像データを同時に学習した点です。これにより、画像の複雑なコンテキストを考慮しつつ、小さな色差に関する伝統的知見も反映したハイブリッドな指標が実現されています。実験では既存のあらゆる指標に対する優位性が示され、密な教師なしで局所色差マップを高精度に生成でき、幾何変形にも強いロバスト性を持つことが確認されました。さらに、CD-iNetによって得られた変換空間は知覚的直交性が高く、色相・彩度・明度の相互干渉が少ない理想的性質を示すことも報告されています。この研究は、パッチレベルから画像レベルまで統合した色差評価の新たな方向性を示したものです。


2025年: 注意機構を組み込んだ色差評価モデル「CD-Attention」

CD-Attention（Qiangら, 陝西科技大学） – 2025年には、中国・陝西科技大学のQiang HuaらがCD-Attentionと呼ばれる手法を発表し、色差評価モデルにトランスフォーマー型注意機構を導入しました。CD-AttentionはCNNとVision Transformer (ViT)のハイブリッド構造で、CNNが局所的な質感・色特徴を抽出し、ViTが画像全体のグローバルな文脈情報を捉えます。さらにViTで得たグローバル特徴に基づき変形畳み込みによる注意マップを生成し、CNNの特徴マップを人間の注目領域に合わせて強調する工夫を行いました。最終的に、高周波成分と低周波成分それぞれに特化した2つのブランチで色差スコアを予測し、重み付き和で統合して最終評価値を得ます。大規模データセットSPCDで検証した結果、CD-Attentionは既存の色差計算法30種類すべてを上回る最先端の精度を達成し、優れた一般化性能を示しました。特に、従来の深層学習モデル（CD-NetやCD-Flow）が局所特徴重視であったのに対し、CD-Attentionはグローバルなシーン理解と局所色差の両面を統合することで、複雑な写真画像における人間の色差知覚をより正確にシミュレートできた点が大きな貢献です。本手法の登場により、深層学習による色差評価はネットワークアーキテクチャの面でも新局面を迎えています。


まとめ

2020年以降、写真画像に対する色差評価は、従来のCIE ΔE式を超えて深層学習によるデータ駆動型手法へと急速に進化しました。大規模データセットSPCDの構築を契機に、CD-NetからCD-Flow、CD-iNet、そしてCD-Attentionへと、モデルは精度と知覚的妥当性の両面で飛躍的進歩を遂げています。これらの研究は、「色と形状は不可分である」という知見を踏まえつつ、深層ネットワークの力で人間視覚に整合する新しい色差尺度を打ち立てました。今後も深層学習を活用した色差評価は、データやモデルの拡充とともに、より高度で汎用的な知覚色差指標へ発展していくと期待されます。

参考文献: 新たな深層学習型色差評価手法の詳細は、それぞれの発表論文（CD-Net、CD-Flow、CD-iNet、CD-Attention）をご参照ください。また、一般的な深層知覚指標についてはLPIPSやDISTSの論文が有用です。各モデルのコードやデータセット（SPCDなど）は公開されており、後続研究に活用されています。



作成日時: 2025-08-25 14:44:37