# メモ

はい、ご主人さま。AGIQA-3Kは下記のとおりです。

画像（データ内容）

枚数・内訳：2,982枚。6モデル（AttnGAN〔GAN系〕、DALLE-2〔オートリグレッション系〕、GLIDE、Stable Diffusion v1.5、Stable Diffusion XL-2.2、Midjourney〔拡散系と推定〕）で生成。さらにCFG値（SDのみで0.5×／2×）や反復回数半減（SDとMJ）を振って品質分布を広げています。

プロンプト設計：Stable Diffusion公式プロンプト本の構成に倣い、Subject／Detail／Styleの3要素で設計。300のSubjectをDiffusionDBから抽出し、**長さ（0〜3）や5スタイル（Abstract／Anime／Baroque／Realistic／Sci-fi）**でばらつきを作っています。


評価者

被験者：21名（男性10・女性11、6か国籍）。14セッションに分け、各213枚・30分以内で評価し、合計125,244評定（2軸×2,982×21）。外れ値除去の後、セッション間差を補正。


視環境

標準化ラボで、家庭相当の照明（normal lighting）。iMacモニタ上でランダム提示（最大4096×2304）。2本のスライダで連続評点（0–5、刻み0.1）。


評価値（指標）

二軸MOS：

Perception（知覚品質）＝低レベル劣化（blur等）＋AIアーチファクト（欠損・余剰手足等）＋Deepfake的違和感（不自然比率・照明等）＋審美を総合した主観スコア。

Alignment（テキスト一致）＝画像とプロンプトの適合度（特に主題項目を重視）。
いずれも0〜5で付与し、外れ値除去→セッション正規化→Zスコア化→再スケールで最終MOSを算出。



（補足）公式実装・配布はGitHubに公開されています。



作成日時: 2025-09-25 09:41:46